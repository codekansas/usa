{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf363839",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "\n",
    "This script demonstrates how to train a model on a pre-collected dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e830d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# These environment variables control where\n",
    "# training and eval logs are written.\n",
    "os.environ[\"RUN_DIR\"] = \"runs\"\n",
    "os.environ[\"EVAL_RUN_DIR\"] = \"eval_runs\"\n",
    "\n",
    "# This is used to set a constant Tensorboard port.\n",
    "os.environ[\"TENSORBOARD_PORT\"] = str(8989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828ca596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import ml.api as ml  # Source: https://github.com/codekansas/ml-starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81dddc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configures logging for the \n",
    "ml.configure_logging(use_tqdm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74232c",
   "metadata": {},
   "source": [
    "The framework used to train the models specifies five parts:\n",
    "\n",
    "1. Model: The USA net model follows the vanilla NeRF implementation, and uses a simple MLP mapping 3D points to an output vector\n",
    "2. Task: This is used to coordinate training by passing the dataset samples to the model and computing the loss function\n",
    "3. Optimizer\n",
    "4. Learning rate scheduler\n",
    "5. Trainer: This "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a9bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "        \"name\": \"point2emb\",          # `register_model` name in `usa.models.point2emb`\n",
    "        \"num_layers\": 4,\n",
    "        \"hidden_dims\": 256,\n",
    "        \"output_dims\": 513,           # CLIP = 512, SDF = 1\n",
    "    },\n",
    "    \"task\": {\n",
    "        \"name\": \"clip_sdf\",           # `register_task` name in `usa.tasks.clip_sdf`\n",
    "        \"dataset\": \"lab_r3d\",         # Pre-collected dataset\n",
    "        \"clip_model\": \"ViT_B_16\",\n",
    "        \"queries\": [\n",
    "            \"Chair\",\n",
    "            \"Shelves\",\n",
    "            \"Man sitting at a computer\",\n",
    "            \"Desktop computers\",\n",
    "            \"Wooden box\",\n",
    "            \"Doorway\",\n",
    "        ],\n",
    "        \"rotate_image\": True,         # Dataset-specific, for visualization purposes\n",
    "        \"finished\": {\n",
    "            \"max_steps\": 10_000,      # Number of training steps\n",
    "        },\n",
    "        \"dataloader\": {\n",
    "            \"train\": {\n",
    "                \"batch_size\": 16,\n",
    "                \"num_workers\": 0,\n",
    "                \"persistent_workers\": False,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"adam\",\n",
    "        \"lr\": 3e-4,\n",
    "    },\n",
    "    \"lr_scheduler\": {\n",
    "        \"name\": \"linear\",\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"name\": \"vanilla_sl\",\n",
    "        \"exp_name\": \"jupyter\",\n",
    "        \"log_dir_name\": \"test\",\n",
    "        \"base_run_dir\": \"runs\",\n",
    "        \"run_id\": 0,\n",
    "        \"checkpoint\": {\n",
    "            \"save_every_n_steps\": 2500,\n",
    "            \"only_save_most_recent\": True,\n",
    "        },\n",
    "        \"validation\": {\n",
    "            \"valid_every_n_steps\": 250,\n",
    "            \"num_init_valid_steps\": 1,\n",
    "        },\n",
    "    },\n",
    "    \"logger\": [{\"name\": \"tensorboard\"}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79ef36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-04-17 12:08:23\u001b[0m [ml.utils.timer] Finished loading pretrained CLIP model in 2.06 seconds\n",
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-04-17 12:08:23\u001b[0m [ml.utils.timer] Finished building clip_sdf from '/private/home/bbolte/Github/usa-net/usa/tasks/clip_sdf.py' in 2.29 seconds\n",
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-04-17 12:08:23\u001b[0m [ml.utils.timer] Finished building task in 2.29 seconds\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-04-17 12:08:23\u001b[0m [ml.trainers.base] Experiment directory: /private/home/bbolte/Github/usa-net/notebooks/runs/jupyter/run_0\n",
      "\u001b[1;35mINFOALL\u001b[0m  \u001b[90m2023-04-17 12:08:23\u001b[0m [ml.utils.device.auto] Device: [cuda:0]\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-04-17 12:08:23\u001b[0m [ml.loggers.tensorboard] Tensorboard command: tensorboard serve --logdir /private/home/bbolte/Github/usa-net/notebooks/runs/jupyter/run_0/test/tensorboard/12-08-21 --bind_all --port 8989 --reload_interval 15\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-04-17 12:08:27\u001b[0m [ml.loggers.tensorboard] Running TensorBoard process:\n",
      "-------------------------------------------------------------------\n",
      "TensorBoard 2.12.2 at http://localhost:8989/ (Press CTRL+C to quit)\n",
      "-------------------------------------------------------------------\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-04-17 12:08:27\u001b[0m [ml.core.registry] Components:\n",
      " ↪ \u001b[32mModel\u001b[0m: \u001b[36musa.models.point2emb.Point2EmbModel\u001b[0m (\u001b[34m/private/home/bbolte/Github/usa-net/usa/models/point2emb.py\u001b[0m)\n",
      " ↪ \u001b[32mTask\u001b[0m: \u001b[36musa.tasks.clip_sdf.ClipSdfTask\u001b[0m (\u001b[34m/private/home/bbolte/Github/usa-net/usa/tasks/clip_sdf.py\u001b[0m)\n",
      " ↪ \u001b[32mTrainer\u001b[0m: \u001b[36mml.trainers.sl.SupervisedLearningVanillaTrainer\u001b[0m (\u001b[34m/private/home/bbolte/.conda/envs/usa-net/lib/python3.10/site-packages/ml/trainers/sl.py\u001b[0m)\n",
      " ↪ \u001b[32mOptimizer\u001b[0m: \u001b[36mml.optimizers.adam.AdamOptimizer\u001b[0m (\u001b[34m/private/home/bbolte/.conda/envs/usa-net/lib/python3.10/site-packages/ml/optimizers/adam.py\u001b[0m)\n",
      " ↪ \u001b[32mLR Scheduler\u001b[0m: \u001b[36mml.lr_schedulers.linear.LinearLRScheduler\u001b[0m (\u001b[34m/private/home/bbolte/.conda/envs/usa-net/lib/python3.10/site-packages/ml/lr_schedulers/linear.py\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "objs = ml.instantiate_config(config)\n",
    "\n",
    "# Unpacking the different components.\n",
    "model = objs.model\n",
    "task = objs.task\n",
    "optimizer = objs.optimizer\n",
    "lr_scheduler = objs.lr_scheduler\n",
    "trainer = objs.trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7cd819",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir /private/home/bbolte/Github/usa-net/notebooks/runs/jupyter/run_0/test/tensorboard/12-08-21 (started 0:00:00 ago; port 8989, pid 1504685).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b65eedde09246797\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b65eedde09246797\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8989;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-04-17 12:08:27\u001b[0m [ml.trainers.base] Overwriting config /private/home/bbolte/Github/usa-net/notebooks/runs/jupyter/run_0/config.yaml:\n",
      " ↪ \u001b[32m+\u001b[0m logger.0.log_id=12-08-21\n",
      " ↪ \u001b[31m-\u001b[0m logger.0.log_id=12-07-10\n",
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-04-17 12:08:29\u001b[0m [ml.utils.timer] Finished building task model in 1.62 seconds\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-04-17 12:08:29\u001b[0m [usa.tasks.datasets.r3d] Preprocessing R3D arrays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading R3D file: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 681/681 [00:03<00:00, 225.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-04-17 12:08:32\u001b[0m [ml.utils.timer] Finished getting datasets in 3.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-04-17 12:08:32\u001b[0m [ml.trainers.mixins.cpu_stats] Starting CPU stats monitor for PID 1504360 with PID 1504872\n",
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-04-17 12:08:33\u001b[0m [ml.utils.timer] Finished initial validation step(s) in 1.26 seconds\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-04-17 12:10:16\u001b[0m [ml.trainers.base] Exiting training job for /private/home/bbolte/Github/usa-net/notebooks/runs/jupyter/run_0/config.yaml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m notebook\u001b[38;5;241m.\u001b[39mdisplay(port\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTENSORBOARD_PORT\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Runs the training loop.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/usa-net/lib/python3.10/site-packages/ml/trainers/sl.py:146\u001b[0m, in \u001b[0;36mSupervisedLearningVanillaTrainer.train\u001b[0;34m(self, model, task, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_step_start\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_step_start(state, train_batch, task, model, optim, lr_sched)\n\u001b[0;32m--> 146\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_sched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_sched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m valid_every_n_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvalidation\u001b[38;5;241m.\u001b[39mvalid_every_n_steps\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_every_n_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m state\u001b[38;5;241m.\u001b[39mnum_steps \u001b[38;5;241m%\u001b[39m valid_every_n_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/usa-net/lib/python3.10/site-packages/ml/trainers/vanilla.py:132\u001b[0m, in \u001b[0;36mVanillaTrainer.train_step\u001b[0;34m(self, task_model, batch, state, task, model, optim, lr_sched)\u001b[0m\n\u001b[1;32m    130\u001b[0m     task_model, state\u001b[38;5;241m.\u001b[39mphase \u001b[38;5;241m=\u001b[39m set_phase(task_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast_context():\n\u001b[0;32m--> 132\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtask_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_single_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    134\u001b[0m     single_loss, loss_names \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mget_single_loss(loss)\n",
      "File \u001b[0;32m~/.conda/envs/usa-net/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/usa-net/lib/python3.10/site-packages/ml/trainers/vanilla.py:64\u001b[0m, in \u001b[0;36mTaskModel.forward\u001b[0;34m(self, batch, state)\u001b[0m\n\u001b[1;32m     62\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mrun_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, batch, state)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mon_after_forward_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, batch, output, state)\n\u001b[0;32m---> 64\u001b[0m loss: Loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mon_after_compute_loss(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, batch, output, loss, state)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Github/usa-net/usa/tasks/clip_sdf.py:198\u001b[0m, in \u001b[0;36mClipSdfTask.compute_loss\u001b[0;34m(self, model, batch, state, output)\u001b[0m\n\u001b[1;32m    194\u001b[0m clip_preds, sdf_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(preds, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip\u001b[38;5;241m.\u001b[39mvisual\u001b[38;5;241m.\u001b[39moutput_dim, \u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# Gets the nearest neighbor to the sampled points.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     batch_xyz \u001b[38;5;241m=\u001b[39m \u001b[43mget_xyz_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintrinsics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     nearest_xyz, nearest_inds \u001b[38;5;241m=\u001b[39m get_nearest_xyz(batch_xyz, xyz\u001b[38;5;241m.\u001b[39mto(pose))\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# Gets the batch ID of the nearest points.\u001b[39;00m\n",
      "File \u001b[0;32m~/Github/usa-net/usa/tasks/datasets/utils.py:146\u001b[0m, in \u001b[0;36mget_xyz_coordinates\u001b[0;34m(depth, mask, pose, intrinsics)\u001b[0m\n\u001b[1;32m    142\u001b[0m depth \u001b[38;5;241m=\u001b[39m depth[flipped_mask]\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Gets the pixel grid.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m xs, ys \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmeshgrid(\n\u001b[0;32m--> 146\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    147\u001b[0m     torch\u001b[38;5;241m.\u001b[39marange(height, device\u001b[38;5;241m=\u001b[39mdepth\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    148\u001b[0m     indexing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    150\u001b[0m xy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([xs, ys], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;28;01mNone\u001b[39;00m, :, :]\u001b[38;5;241m.\u001b[39mrepeat_interleave(bsz, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    151\u001b[0m xy \u001b[38;5;241m=\u001b[39m xy[flipped_mask\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "# Show Tensorboard inside the notebook.\n",
    "notebook.display(port=int(os.environ['TENSORBOARD_PORT']))\n",
    "\n",
    "# Runs the training loop.\n",
    "trainer.train(model, task, optimizer, lr_scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
