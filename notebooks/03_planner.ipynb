{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b54212e",
   "metadata": {},
   "source": [
    "# Gradient-based planner\n",
    "\n",
    "This notebook demonstrates how to build a gradient-based planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# These environment variables control where training and eval logs are written.\n",
    "# You can set these in your shell profile as well.\n",
    "os.environ[\"RUN_DIR\"] = \"runs\"\n",
    "os.environ[\"EVAL_RUN_DIR\"] = \"eval_runs\"\n",
    "os.environ[\"MODEL_DIR\"] = \"models\"\n",
    "os.environ[\"DATA_DIR\"] = \"data\"\n",
    "\n",
    "# This is used to set a constant Tensorboard port.\n",
    "os.environ[\"TENSORBOARD_PORT\"] = str(8989)\n",
    "\n",
    "import ml.api as ml  # Source: https://github.com/codekansas/ml-starter\n",
    "\n",
    "# Enables logging to `stdout`.\n",
    "ml.configure_logging(use_tqdm=True)\n",
    "\n",
    "# Imports these files to add them to the model and task registry.\n",
    "from usa.models.point2emb import Point2EmbModel\n",
    "from usa.tasks.clip_sdf import ClipSdfTask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8138cf",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "For this example, we use a clip recorded using the code in the `home-robot` repository [here](https://github.com/facebookresearch/home-robot). You can record your own clip on the Stretch robot and use that instead, by substituting the dataset path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "data_root = Path(\"data\")\n",
    "data_root.mkdir(exist_ok=True)\n",
    "dataset_path = data_root / \"dataset.pkl\"\n",
    "\n",
    "# We're downloading an existing dataset, but you can use your own instead.\n",
    "dataset_url = \"https://github.com/codekansas/usa/releases/download/v0.0.2/chris_lab.pkl\"\n",
    "if not dataset_path.exists():\n",
    "    with requests.get(dataset_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(dataset_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "# Using the default config, but overriding the dataset.\n",
    "config = OmegaConf.load(\"config.yaml\")\n",
    "config.task.dataset = \"home_robot\"\n",
    "config.task.dataset_path = str(dataset_path)\n",
    "\n",
    "# We're using a small number of training steps to make the example easier\n",
    "# to follow, but this can be configured to improve the model quality.\n",
    "config.task.finished.max_steps = 500\n",
    "\n",
    "# We also only use the Tensorboard logger since it is easier to read.\n",
    "config.logger = [{\"name\": \"tensorboard\"}]\n",
    "\n",
    "# We still need to explicitly set these variables.\n",
    "config.trainer.exp_name = \"jupyter\"\n",
    "config.trainer.log_dir_name = \"test\"\n",
    "config.trainer.base_run_dir = \"runs\"\n",
    "config.trainer.run_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac722a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = ml.instantiate_config(config)\n",
    "\n",
    "# Unpacking the different components.\n",
    "model = objs.model\n",
    "task = objs.task\n",
    "optimizer = objs.optimizer\n",
    "lr_scheduler = objs.lr_scheduler\n",
    "trainer = objs.trainer\n",
    "\n",
    "from tensorboard import notebook\n",
    "\n",
    "# Show Tensorboard inside the notebook.\n",
    "notebook.display(port=int(os.environ['TENSORBOARD_PORT']))\n",
    "\n",
    "# Runs the training loop.\n",
    "trainer.train(model, task, optimizer, lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a1a95",
   "metadata": {},
   "source": [
    "## Building a planner\n",
    "\n",
    "This example demonstrates how to use the trained model to build a planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea438613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from usa.planners.clip_sdf import GradientPlanner\n",
    "\n",
    "# Builds the planner from the model and task. The planner\n",
    "# hyperparameters can be configured as needed.\n",
    "planner = GradientPlanner(\n",
    "    dataset=task._dataset(),\n",
    "    model=model,\n",
    "    task=task,\n",
    "    device=task._device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate waypoints between two explicit points.\n",
    "waypoints = planner.plan(start_xy=(0, 0), end_xy=(1, 1))\n",
    "\n",
    "# Generates waypoints from a start location to a semantic target.\n",
    "waypoints = planner.plan(start_xy=(0, 0), end_goal=\"The chair\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
